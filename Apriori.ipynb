{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M', 'O', 'N', 'K', 'E', 'Y'],\n",
       " ['D', 'O', 'N', 'K', 'E', 'Y'],\n",
       " ['M', 'A', 'K', 'E'],\n",
       " ['M', 'U', 'C', 'K', 'Y'],\n",
       " ['C', 'O', 'O', 'K', 'I', 'E'],\n",
       " ['M', 'O', 'O', 'K', 'A', 'C', 'K', 'Y'],\n",
       " ['H', 'O', 'O', 'K', 'C', 'O', 'O'],\n",
       " ['H', 'O', 'C', 'K', 'E', 'Y', 'H', 'O', 'O'],\n",
       " ['P', 'O', 'N', 'Y', 'O', 'N', 'E', 'Y'],\n",
       " ['R', 'O', 'C', 'K', 'Y'],\n",
       " ['M', 'O', 'C', 'K', 'Y'],\n",
       " ['C', 'O', 'C', 'K', 'Y'],\n",
       " ['S', 'O', 'C', 'K', 'E', 'Y']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['M', 'O', 'N', 'K', 'E', 'Y'],\n",
    "        ['D', 'O', 'N', 'K', 'E', 'Y'],\n",
    "        ['M', 'A', 'K', 'E'],\n",
    "        ['M', 'U', 'C', 'K', 'Y'],\n",
    "        ['C', 'O', 'O', 'K', 'I', 'E']]\n",
    "data.append(list('MOOKACKY'))\n",
    "data.append(list('HOOKCOO'))\n",
    "data.append(list('HOCKEYHOO'))\n",
    "data.append(list('PONYONEY'))\n",
    "data.append(list('ROCKY'))\n",
    "data.append(list('MOCKY'))\n",
    "data.append(list('COCKY'))\n",
    "data.append(list('SOCKEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "实现基于计数散列表的Apriori关联类 1950097阙成恩\n",
    "'''\n",
    "class Apriori():\n",
    "    # 初始化数据集为set类型，定义最小支持度和最小置信度\n",
    "    def __init__(self, data: list, min_sup: float, min_conf: float):\n",
    "        self.dataset = [set(x) for x in data]\n",
    "        self.min_sup = min_sup\n",
    "        self.min_conf = min_conf\n",
    "    \n",
    "    # 根据集合计算hash\n",
    "    def get_key(self, lis: set) -> str: \n",
    "        lis = [ord(i) for i in lis]\n",
    "        lis.sort()\n",
    "        lis = [str(i) for i in lis]\n",
    "        return ''.join(lis)\n",
    "    \n",
    "    # 从hash反算集合\n",
    "    def get_set(self, key: str) -> set:\n",
    "        return set([chr(int(key[2*i:2*i+2])) for i in range(len(key)//2)])\n",
    "    \n",
    "    # 是否符合apriori剪枝规则\n",
    "    def is_apriori(self, Ck_key: str, Lk_keys: list) -> bool: \n",
    "        Ck_set = self.get_set(Ck_key)\n",
    "        Lk_sets = [self.get_set(Lk_key) for Lk_key in Lk_keys]\n",
    "        \n",
    "        for item in Ck_set:\n",
    "            sub_Ck = Ck_set - frozenset([item])\n",
    "            if sub_Ck not in Lk_sets:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # 计算C1候选散列表，索引为get_key计算得到的hash，值为遍历原数据集得到的计数结果的支持度\n",
    "    def get_C1(self) -> dict:\n",
    "        C1  = {}\n",
    "        \n",
    "        for itemset in self.dataset:\n",
    "            for item in itemset:\n",
    "                key = self.get_key(item)\n",
    "                if key not in C1:\n",
    "                    C1[key] = 1\n",
    "                else:\n",
    "                    C1[key] += 1    \n",
    "                        \n",
    "        for key in C1:\n",
    "            C1[key] = C1[key] / len(self.dataset) \n",
    "\n",
    "        return C1\n",
    "    \n",
    "    # 根据Ck候选散列表计算Lk频繁散列表\n",
    "    def generate_Lk(self, Ck: dict, k: int) -> dict:\n",
    "        Lk = {}\n",
    "        \n",
    "        for key in Ck:\n",
    "            if Ck[key] >= self.min_sup:\n",
    "                Lk[key] = Ck[key]\n",
    "        return Lk\n",
    "    \n",
    "    # 根据Lk候选散列表，拼接组合索引，根据apriori规则进行剪枝，并遍历原数据集计算Lk频繁散列表（支持度）    \n",
    "    def generate_Ck(self, Lk, k):\n",
    "        Ck = {}\n",
    "        Lk_keys = list(Lk.keys())\n",
    "        \n",
    "        for i in range(len(Lk_keys)):\n",
    "            for j in range(i+1, len(Lk_keys)):\n",
    "                set0 = self.get_set(Lk_keys[i])\n",
    "                set1 = self.get_set(Lk_keys[j])\n",
    "\n",
    "                if len(set0 & set1) == k-2:\n",
    "                    new_set = set0 | set1\n",
    "                    Ck_key = self.get_key(new_set)\n",
    "                    \n",
    "                    if self.is_apriori(Ck_key,Lk_keys):\n",
    "                        # print(set0, set1)\n",
    "                        Ck[Ck_key] = 0\n",
    "                        \n",
    "                        for itemset in self.dataset:\n",
    "                            if new_set.issubset(itemset):\n",
    "                                Ck[Ck_key] += 1\n",
    "\n",
    "        for Ck_key in Ck:\n",
    "            Ck[Ck_key] = Ck[Ck_key] / len(self.dataset)\n",
    "            \n",
    "        return Ck\n",
    "    \n",
    "    # 计算最大频繁项集X\n",
    "    def generate_X(self) -> dict:\n",
    "        k = 1\n",
    "        Ck = self.get_C1()\n",
    "        Lk = self.generate_Lk(Ck,k=k)\n",
    "        \n",
    "        while True:\n",
    "            k+=1\n",
    "            Ck = self.generate_Ck(Lk,k)\n",
    "            if len(Ck) == 0:\n",
    "                return Lk\n",
    "            Lk = self.generate_Lk(Ck,k)\n",
    "\n",
    "    # 回溯算法，计算一个长为k的集合的所有可能子集，返回二进制的01表示链表\n",
    "    def all_subsets(self, k: int) -> list:\n",
    "        path = []\n",
    "        res = []\n",
    "        def backtrack():\n",
    "            # 归\n",
    "            if len(path) == k:\n",
    "                res.append(path[:])\n",
    "            else:\n",
    "                for i in [0,1]:\n",
    "                    path.append(i)\n",
    "            # 递\n",
    "                    backtrack()\n",
    "                    # print(self.path)\n",
    "                    path.pop()\n",
    "            return res\n",
    "        return backtrack()\n",
    "    \n",
    "    # 对所有的最大频繁项集，分别计算它们的关联规则并输出    \n",
    "    def rules(self):\n",
    "        # 得到最大频繁项集\n",
    "        X = self.generate_X()\n",
    "        for freq_key in X:\n",
    "            freq_set = self.get_set(freq_key)\n",
    "            freq_lis = list(freq_set)\n",
    "            \n",
    "            # 计算所有可能的真子集\n",
    "            bin_subsets = self.all_subsets(len(freq_lis))\n",
    "            possible_subsets = []\n",
    "            for i in bin_subsets:\n",
    "                subset = []\n",
    "                for j in range(len(i)):\n",
    "                    if i[j] == 1:\n",
    "                        subset.append(freq_lis[j])\n",
    "                possible_subsets.append(set(subset))\n",
    "            # 删去非真子集\n",
    "            possible_subsets.pop(0)   \n",
    "            possible_subsets.pop(-1)  \n",
    "            \n",
    "            # 计算置信度并输出符合要求的关联规则\n",
    "            for sub_set in possible_subsets:                \n",
    "                sub_count = 0\n",
    "                count = X[freq_key] * len(self.dataset)\n",
    "                for key in self.dataset:\n",
    "                    if sub_set.issubset(key):\n",
    "                        sub_count += 1\n",
    "                if (count / sub_count) >= self.min_conf:\n",
    "                    print(freq_set,':',sub_set, '--->', freq_set - sub_set,'conf:',(count / sub_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "relator = Apriori(data=data, min_sup=0.6, min_conf=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'757989': 0.6153846153846154, '677579': 0.6153846153846154}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relator.generate_X()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K', 'Y', 'O'} : {'O'} ---> {'K', 'Y'} conf: 0.7272727272727273\n",
      "{'K', 'Y', 'O'} : {'Y'} ---> {'K', 'O'} conf: 0.8\n",
      "{'K', 'Y', 'O'} : {'O', 'Y'} ---> {'K'} conf: 0.8888888888888888\n",
      "{'K', 'Y', 'O'} : {'K'} ---> {'O', 'Y'} conf: 0.6666666666666666\n",
      "{'K', 'Y', 'O'} : {'K', 'O'} ---> {'Y'} conf: 0.8\n",
      "{'K', 'Y', 'O'} : {'K', 'Y'} ---> {'O'} conf: 0.8888888888888888\n",
      "{'K', 'C', 'O'} : {'O'} ---> {'K', 'C'} conf: 0.7272727272727273\n",
      "{'K', 'C', 'O'} : {'C'} ---> {'K', 'O'} conf: 0.8888888888888888\n",
      "{'K', 'C', 'O'} : {'C', 'O'} ---> {'K'} conf: 1.0\n",
      "{'K', 'C', 'O'} : {'K'} ---> {'C', 'O'} conf: 0.6666666666666666\n",
      "{'K', 'C', 'O'} : {'K', 'O'} ---> {'C'} conf: 0.8\n",
      "{'K', 'C', 'O'} : {'K', 'C'} ---> {'O'} conf: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "relator.rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M', 'O', 'N', 'K', 'E', 'Y'],\n",
       " ['D', 'O', 'N', 'K', 'E', 'Y'],\n",
       " ['M', 'A', 'K', 'E'],\n",
       " ['M', 'U', 'C', 'K', 'Y'],\n",
       " ['C', 'O', 'O', 'K', 'I', 'E'],\n",
       " ['M', 'O', 'O', 'K', 'A', 'C', 'K', 'Y'],\n",
       " ['H', 'O', 'O', 'K', 'C', 'O', 'O'],\n",
       " ['H', 'O', 'C', 'K', 'E', 'Y', 'H', 'O', 'O'],\n",
       " ['P', 'O', 'N', 'Y', 'O', 'N', 'E', 'Y'],\n",
       " ['R', 'O', 'C', 'K', 'Y'],\n",
       " ['M', 'O', 'C', 'K', 'Y'],\n",
       " ['C', 'O', 'C', 'K', 'Y'],\n",
       " ['S', 'O', 'C', 'K', 'E', 'Y']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc389f016b4508cd8daa88f4ee394fd1693d7bd89433f66362fdc17b674936ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
